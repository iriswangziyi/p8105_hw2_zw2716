Homework 2
================
Iris (Ziyi) Wang

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

First, define a path to the dataset.

``` r
path_to_data = "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx"
```

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
    read_xlsx(
        path = path_to_data,
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
    )
```

Read precipitation data\! For 2018 and 2017.

``` r
precip_2018 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx",
        sheet = "2018 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2018) %>% 
    relocate(year)

precip_2017 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx",
        sheet = "2017 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2017) %>% 
    relocate(year)
```

Now combine annual precipitation dataframes. In the following code
chunk, I create a “helper” tibble that contains pairs of numeric and
character ways of representing month, and then merge that (using month
number as a key) with the precipitation dataset. This technique is one I
use often when I need to recode a moderate or large number of values for
a variable.

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )

precip_df = 
    bind_rows(precip_2018, precip_2017)

precip_df =
    left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 416 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

First, define a path to Problem 2 dataset.

``` r
path_to_P2_data = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
```

Read the NYC Transit dataset, only retain line, station name, station
latitude / longitude, routes served, entry, vending, entrance type, and
ADA compliance from the dataset.

``` r
nyc_subway_df = read_csv(path_to_P2_data) %>% 
    select(c("Line", "Station Name", "Station Latitude", "Station Longitude", 
             "Route1", "Route2", "Route3", "Route4", "Route5", "Route6", 
             "Route7", "Route8", "Route9", "Route10", "Route11", 
             "Entrance Type", "Entry", "Vending", "ADA")) %>% 
    janitor::clean_names() %>% 
    mutate(entry = recode(entry, "YES" = T, "NO" = F))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

explain briefly describe your data cleaning steps so far, and give the
dimension (rows x columns) of the resulting dataset. Are these data
tidy?

The variables in the NYC Transit dataset, called **nyc\_subway\_df**
are: line, station name, station latitude, station longitude, routes
served (1-11), entrance type, entry, vending, and ADA (compliance).  
For my data cleaning step, I have changed all the variables name to be
more readable and easy to work with (all lowercased, use "\_" instead of
" "). I also convert the entry variable from character to a logical
variable.  
The dimension of resulting dataset **nyc\_subway\_df** is 416 x 14. The
dataset is tidy now.

In this dataset:  
\* There are X distinct stations. \* X stations are ADA compliant. \*
The proportion of station entrances / exits without vending allow
entrance is X.

How many distinct stations are there? Note that stations are identified
both by name and by line (e.g. 125th St A/B/C/D; 125st 1; 125st 4/5);
the distinct function may be useful here.

## Problem 3
